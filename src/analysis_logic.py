"""
í•µì‹¬ ë¶„ì„ ë¡œì§ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ëª¨ë“ˆ (Stateless API ë²„ì „).

RAG íŒŒì´í”„ë¼ì¸ì˜ ì „ì²´ íë¦„ì„ ì¡°ìœ¨í•©ë‹ˆë‹¤:
    1. ìºì‹œ í™•ì¸ (HistoryManager)
    2. HyDE + Multi-Query ê²€ìƒ‰
    3. Cross-Encoder ì¬ì •ë ¬ (Reranker)
    4. LLM ê´€ë ¨ì„± í‰ê°€ (Grading)
    5. ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ (Streaming CoT Analysis)
"""
from __future__ import annotations

import asyncio
import logging
import time
from datetime import datetime
from typing import Any, AsyncGenerator, Dict, List, Optional

from src.patent_agent import PatentAgent, PatentSearchResult

logger = logging.getLogger(__name__)

# =============================================================================
# Reranker ì‹±ê¸€í„´ ìºì‹œ (ëª¨ë“ˆ ìˆ˜ì¤€ ì§€ì—° ì´ˆê¸°í™”)
# =============================================================================

# RerankerëŠ” ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë”© ë¹„ìš©ì´ í¬ë¯€ë¡œ ì „ì—­ ì‹±ê¸€í„´ìœ¼ë¡œ ê´€ë¦¬
_reranker_instance: Optional[Any] = None


def get_reranker() -> Optional[Any]:
    """Reranker ëª¨ë¸ì„ ì§€ì—° ë¡œë“œí•˜ì—¬ ì‹±ê¸€í„´ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    ìµœì´ˆ í˜¸ì¶œ ì‹œ ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , ì´í›„ í˜¸ì¶œì—ì„œëŠ” ìºì‹œëœ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ë¡œë“œì— ì‹¤íŒ¨í•˜ë©´ Noneì„ ë°˜í™˜í•˜ë©° ì¬ì‹œë„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (False ì„¼í‹°ë„¬ íŒ¨í„´).

    Returns:
        ì´ˆê¸°í™”ëœ Reranker ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” None (ë¡œë“œ ì‹¤íŒ¨ ì‹œ).
    """
    global _reranker_instance  # noqa: PLW0603

    if _reranker_instance is None:
        try:
            from src.reranker import Reranker  # ìˆœí™˜ ì„í¬íŠ¸ ë°©ì§€ìš© ì§€ì—° ì„í¬íŠ¸

            instance = Reranker()
            # is_available í”„ë¡œí¼í‹°ë¡œ ëª¨ë¸ ë¡œë“œ ì„±ê³µ ì—¬ë¶€ í™•ì¸
            _reranker_instance = instance if instance.is_available else False  # type: ignore[assignment]
        except Exception:
            logger.exception("Reranker ë¡œë“œ ì‹¤íŒ¨. Reranker ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            _reranker_instance = False  # type: ignore[assignment]

    # False(ì‹¤íŒ¨ ì„¼í‹°ë„¬)ì¸ ê²½ìš° None ë°˜í™˜
    return _reranker_instance if _reranker_instance else None  # type: ignore[return-value]


# =============================================================================
# ë‚´ë¶€ í—¬í¼: ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ ì‹¤í–‰
# =============================================================================


async def _run_analysis_streaming(
    agent: PatentAgent,
    user_idea: str,
    results: List[PatentSearchResult],
) -> AsyncGenerator[Dict[str, Any], None]:
    """ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ì„ ì‹¤í–‰í•˜ê³  í† í°/ì „ì²´ í…ìŠ¤íŠ¸ ì´ë²¤íŠ¸ë¥¼ yieldí•©ë‹ˆë‹¤.

    Args:
        agent: ì´ˆê¸°í™”ëœ PatentAgent ì¸ìŠ¤í„´ìŠ¤.
        user_idea: ì‚¬ìš©ì ì•„ì´ë””ì–´ í…ìŠ¤íŠ¸.
        results: ê²€ìƒ‰ ë° ì¬ì •ë ¬ëœ íŠ¹í—ˆ ê²°ê³¼ ëª©ë¡.

    Yields:
        {"type": "stream_token", "content": str} â€” ê° ìŠ¤íŠ¸ë¦¬ë° í† í°.
        {"type": "stream_full", "content": str} â€” ì™„ì „í•œ ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸.
    """
    full_text: str = ""
    async for token in agent.critical_analysis_stream(user_idea, results):
        full_text += token
        yield {"type": "stream_token", "content": token}

    yield {"type": "stream_full", "content": full_text}


# =============================================================================
# ê³µê°œ API: ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸
# =============================================================================


async def run_full_analysis(
    user_idea: str,
    user_id: str,
    db_client: Any,
    history_manager: Optional[Any] = None,
    use_hybrid: bool = True,
    ipc_filters: Optional[List[str]] = None,
) -> AsyncGenerator[Dict[str, Any], None]:
    """ì™„ì „í•œ íŠ¹í—ˆ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.

    ì§„í–‰ ìƒíƒœ, ìŠ¤íŠ¸ë¦¬ë° í† í°, ìµœì¢… ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ ì´ë²¤íŠ¸ë¡œ yieldí•©ë‹ˆë‹¤.

    Args:
        user_idea: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì•„ì´ë””ì–´ í…ìŠ¤íŠ¸.
        user_id: ë¶„ì„ ê²°ê³¼ ìºì‹±ì„ ìœ„í•œ ì‚¬ìš©ì ì‹ë³„ì.
        db_client: ì´ˆê¸°í™”ëœ ë²¡í„° DB í´ë¼ì´ì–¸íŠ¸ (PineconeClient ë“±).
        history_manager: ê²°ê³¼ ìºì‹±ì„ ìœ„í•œ HistoryManager ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒ).
        use_hybrid: Trueë©´ Dense+Sparse í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš©.
        ipc_filters: IPC ì½”ë“œ ì ‘ë‘ì–´ í•„í„° ëª©ë¡ (ì˜ˆ: ['G06', 'H04']).

    Yields:
        ë‹¤ì–‘í•œ typeì˜ ë”•ì…”ë„ˆë¦¬ ì´ë²¤íŠ¸:
        - "info": ìƒíƒœ ë©”ì‹œì§€
        - "progress": ì§„í–‰ë¥  ë° ë©”ì‹œì§€
        - "step_info": ë‹¨ê³„ë³„ ìƒì„¸ ì •ë³´
        - "queries": ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ëª©ë¡
        - "stream_token": LLM ìŠ¤íŠ¸ë¦¬ë° í† í°
        - "result": ìµœì¢… ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    # ------------------------------------------------------------------
    # 0. ìºì‹œ í™•ì¸
    # ------------------------------------------------------------------
    if history_manager and not ipc_filters:
        cached_result = history_manager.find_cached_result(user_idea, user_id)
        if cached_result:
            yield {"type": "info", "message": "âš¡ ì´ë¯¸ ë¶„ì„ëœ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤. ì €ì¥ëœ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."}
            await asyncio.sleep(0.5)
            yield {"type": "result", "data": cached_result}
            return

    # ------------------------------------------------------------------
    # 1. ì—ì´ì „íŠ¸ ë° Reranker ì´ˆê¸°í™”
    # ------------------------------------------------------------------
    agent = PatentAgent(db_client=db_client)
    reranker = get_reranker()

    results: List[PatentSearchResult] = []
    start_time: float = time.monotonic()  # perf counter ì‚¬ìš© (ì ˆëŒ€ ì‹œê°„ ë¶ˆí•„ìš”)

    yield {"type": "progress", "percent": 0, "message": "ğŸš€ ë¶„ì„ ì‹œì‘..."}

    # ------------------------------------------------------------------
    # 2. Step 1: HyDE ê°€ìƒ ì²­êµ¬í•­ ìƒì„± (~3ì´ˆ)
    # ------------------------------------------------------------------
    yield {
        "type": "progress",
        "percent": 5,
        "message": "ğŸ“ Step 1/5: ê°€ìƒ ì²­êµ¬í•­ ìƒì„± ì¤‘... (ì˜ˆìƒ: 3ì´ˆ)",
    }
    yield {"type": "step_info", "step": 1, "message": "HyDE - ê°€ìƒ ì²­êµ¬í•­ ìƒì„± ì¤‘..."}

    await agent.generate_hypothetical_claim(user_idea)

    yield {"type": "progress", "percent": 20, "message": "âœ… Step 1 ì™„ë£Œ!"}

    # ------------------------------------------------------------------
    # 3. Step 2: Multi-Query í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (~4ì´ˆ)
    # ------------------------------------------------------------------
    search_type = "Multi-Query Hybrid" if use_hybrid else "Multi-Query Dense"
    if ipc_filters:
        search_type += f" (IPC í•„í„°: {', '.join(ipc_filters)})"

    yield {
        "type": "progress",
        "percent": 25,
        "message": f"ğŸ” Step 2/5: {search_type} ê²€ìƒ‰ ì¤‘... (ì˜ˆìƒ: 4ì´ˆ)",
    }
    yield {
        "type": "step_info",
        "step": 2,
        "message": f"{search_type} ê²€ìƒ‰ ì¤‘... (3ê°€ì§€ ê´€ì )",
    }

    # Top-15 í›„ë³´ ê²€ìƒ‰
    queries, search_results = await agent.search_multi_query(
        user_idea,
        top_k=15,
        use_hybrid=use_hybrid,
        ipc_filters=ipc_filters,
    )

    yield {"type": "queries", "data": queries}
    yield {"type": "progress", "percent": 45, "message": "âœ… Step 2 ì™„ë£Œ!"}
    yield {
        "type": "info",
        "message": f"âœ… {len(search_results)}ê°œ í›„ë³´ íŠ¹í—ˆ ë°œê²¬ (ì¤‘ë³µ ì œê±°ë¨)",
    }

    # ------------------------------------------------------------------
    # 4. Step 3: Cross-Encoder ì¬ì •ë ¬ (~3ì´ˆ)
    # ------------------------------------------------------------------
    if reranker and search_results:
        yield {
            "type": "progress",
            "percent": 50,
            "message": "ğŸ¯ Step 3/5: Cross-Encoder ì •ë°€ ì¬ì •ë ¬ ì¤‘... (ì˜ˆìƒ: 3ì´ˆ)",
        }
        yield {
            "type": "step_info",
            "step": 3,
            "message": "Cross-Encoder ì •ë°€ ì¬ì •ë ¬ ì¤‘...",
        }

        # reranker.rerank()ëŠ” CPU ë¸”ë¡œí‚¹ ë™ê¸° ì—°ì‚°ì´ë¯€ë¡œ
        # asyncio.to_thread()ë¡œ ìŠ¤ë ˆë“œí’€ì—ì„œ ì‹¤í–‰í•˜ì—¬ ì´ë²¤íŠ¸ ë£¨í”„ë¥¼ ë³´í˜¸
        docs_for_rerank: List[Dict[str, Any]] = [
            {
                "doc_obj": r,  # ì›ë³¸ ê°ì²´ ì°¸ì¡° ë³´ì¡´
                "title": r.title,
                "abstract": r.abstract,
                "claims": r.claims,
            }
            for r in search_results
        ]
        reranked_docs = await asyncio.to_thread(
            reranker.rerank, user_idea, docs_for_rerank, top_k=5
        )

        results = [doc["doc_obj"] for doc in reranked_docs]
        yield {"type": "info", "message": "âœ… Top 5 íŠ¹í—ˆ ì„ ì • ì™„ë£Œ (Reranked)"}
    else:
        results = search_results[:5]
        yield {"type": "info", "message": "âš ï¸ Reranker ë¯¸ì‚¬ìš© (Top 5 ë°˜í™˜)"}

    yield {"type": "progress", "percent": 60, "message": "âœ… Step 3 ì™„ë£Œ!"}

    # ------------------------------------------------------------------
    # 5. Step 4: LLM ê´€ë ¨ì„± í‰ê°€ (~3ì´ˆ)
    # ------------------------------------------------------------------
    yield {
        "type": "progress",
        "percent": 65,
        "message": "ğŸ“Š Step 4/5: ê´€ë ¨ì„± í‰ê°€ ì¤‘... (ì˜ˆìƒ: 3ì´ˆ)",
    }
    yield {"type": "step_info", "step": 4, "message": "LLM ê´€ë ¨ì„± í‰ê°€ ì¤‘..."}

    grading = await agent.grade_results(user_idea, results)

    yield {"type": "progress", "percent": 80, "message": "âœ… Step 4 ì™„ë£Œ!"}
    yield {
        "type": "info",
        "message": f"âœ… í‰ê·  ê´€ë ¨ì„± ì ìˆ˜: {grading.average_score:.2f}",
    }

    # ------------------------------------------------------------------
    # 6. Step 5: AI ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ (~10ì´ˆ)
    # ------------------------------------------------------------------
    yield {
        "type": "progress",
        "percent": 85,
        "message": "ğŸ§  Step 5/5: AI ë¶„ì„ ìŠ¤íŠ¸ë¦¬ë° ì¤‘... (ì˜ˆìƒ: 10ì´ˆ)",
    }
    yield {
        "type": "step_info",
        "step": 5,
        "message": "AIê°€ ë¶„ì„ ë‚´ìš©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤...",
    }

    streamed_text: str = ""
    async for stream_event in _run_analysis_streaming(agent, user_idea, results):
        if stream_event["type"] == "stream_token":
            yield {"type": "stream_token", "content": stream_event["content"]}
        elif stream_event["type"] == "stream_full":
            streamed_text = stream_event["content"]

    # ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ ê²½ëŸ‰ ëª¨ë¸(GPT-4o-mini)ìœ¼ë¡œ JSON êµ¬ì¡°í™” íŒŒì‹± (ë¹„ìš© ì ˆê°)
    # ê¸°ì¡´: GPT-4o 2ì°¨ í˜¸ì¶œ â†’ ìµœì í™”: GPT-4o-mini íŒŒì‹± (~50% ë¹„ìš© ì ˆê°)
    analysis = await agent.parse_streaming_to_structured(user_idea, streamed_text, results)

    # ------------------------------------------------------------------
    # 7. ìµœì¢… ê²°ê³¼ ì¡°í•© ë° yield
    # ------------------------------------------------------------------
    elapsed: float = time.monotonic() - start_time
    yield {
        "type": "progress",
        "percent": 100,
        "message": f"âœ… ë¶„ì„ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ)",
    }

    final_result: Dict[str, Any] = {
        "user_idea": user_idea,
        "search_results": [
            {
                "patent_id": getattr(r, "publication_number", str(getattr(r, "id", ""))),
                "title": r.title,
                "abstract": r.abstract,
                "claims": r.claims,
                "grading_score": getattr(r, "grading_score", 0.0),
                "grading_reason": getattr(r, "grading_reason", ""),
                "rrf_score": getattr(r, "rrf_score", 0.0),
            }
            for r in results
        ],
        "analysis": {
            "similarity": {
                "score": getattr(analysis.similarity, "score", 0),
                "common_elements": getattr(analysis.similarity, "common_elements", []),
                "summary": getattr(analysis.similarity, "summary", ""),
                "evidence": getattr(analysis.similarity, "evidence_patents", []),
            },
            "infringement": {
                "risk_level": getattr(analysis.infringement, "risk_level", "unknown"),
                "risk_factors": getattr(analysis.infringement, "risk_factors", []),
                "summary": getattr(analysis.infringement, "summary", ""),
                "evidence": getattr(analysis.infringement, "evidence_patents", []),
            },
            "avoidance": {
                "strategies": getattr(analysis.avoidance, "strategies", []),
                "alternatives": getattr(analysis.avoidance, "alternative_technologies", []),
                "summary": getattr(analysis.avoidance, "summary", ""),
                "evidence": getattr(analysis.avoidance, "evidence_patents", []),
            },
            "component_comparison": {
                "idea_components": getattr(
                    analysis.component_comparison, "idea_components", []
                ),
                "matched_components": getattr(
                    analysis.component_comparison, "matched_components", []
                ),
                "unmatched_components": getattr(
                    analysis.component_comparison, "unmatched_components", []
                ),
                "risk_components": getattr(
                    analysis.component_comparison, "risk_components", []
                ),
            },
            "conclusion": getattr(analysis, "conclusion", ""),
        },
        "streamed_analysis": streamed_text,
        "timestamp": datetime.now().isoformat(),
        "search_type": "hybrid" if use_hybrid else "dense",
    }

    yield {"type": "result", "data": final_result}
