"""
Core analysis logic orchestration (Stateless API version).
"""
import time
import asyncio
from typing import AsyncGenerator, Dict, Any, List, Optional
from datetime import datetime

from src.patent_agent import PatentAgent
from src.history_manager import HistoryManager

# Global singleton cache for reranker (to replace @st.cache_resource)
_RERANKER_INSTANCE = None

def get_reranker():
    """Load Reranker model (cached)."""
    global _RERANKER_INSTANCE
    if _RERANKER_INSTANCE is None:
        try:
            from src.reranker import Reranker
            _RERANKER_INSTANCE = Reranker()
        except Exception as e:
            print(f"Reranker load failed: {e}")
            _RERANKER_INSTANCE = False # Failed, don't try again
    return _RERANKER_INSTANCE if _RERANKER_INSTANCE else None


async def run_analysis_streaming(agent, user_idea: str, results) -> AsyncGenerator[Dict[str, Any], None]:
    """Run streaming analysis and yield tokens."""
    full_text = ""
    async for token in agent.critical_analysis_stream(user_idea, results):
        full_text += token
        yield {"type": "stream_token", "content": token}
    
    yield {"type": "stream_full", "content": full_text}


async def run_full_analysis(
    user_idea: str, 
    user_id: str,
    db_client, 
    history_manager: Optional[HistoryManager] = None,
    use_hybrid: bool = True,
    ipc_filters: list = None
) -> AsyncGenerator[Dict[str, Any], None]:
    """
    Run the complete patent analysis with streaming.
    Yields dictionary events such as progress updates, stream tokens, and the final result.
    """
    
    # Check for cached result first
    if history_manager and not ipc_filters:
        cached_result = history_manager.find_cached_result(user_idea, user_id)
        if cached_result:
            yield {"type": "info", "message": "âš¡ ì´ë¯¸ ë¶„ì„ëœ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤. ì €ì¥ëœ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."}
            await asyncio.sleep(0.5)
            yield {"type": "result", "data": cached_result}
            return

    # Create agent with cached DB client
    agent = PatentAgent(db_client=db_client)
    
    # Load Reranker
    reranker = get_reranker()
    
    results = []
    start_time = time.time()
    
    # Progress bar init
    yield {"type": "progress", "percent": 0, "message": "ğŸš€ ë¶„ì„ ì‹œì‘..."}
    
    # Step 1: HyDE (~3ì´ˆ)
    yield {"type": "progress", "percent": 5, "message": "ğŸ“ Step 1/5: ê°€ìƒ ì²­êµ¬í•­ ìƒì„± ì¤‘... (ì˜ˆìƒ: 3ì´ˆ)"}
    yield {"type": "step_info", "step": 1, "message": "HyDE - ê°€ìƒ ì²­êµ¬í•­ ìƒì„± ì¤‘..."}
    hypothetical_claim = await agent.generate_hypothetical_claim(user_idea)
    yield {"type": "progress", "percent": 20, "message": "âœ… Step 1 ì™„ë£Œ!"}
    
    # Step 2: Multi-Query Search (~4ì´ˆ)
    search_type = "Multi-Query Hybrid" if use_hybrid else "Multi-Query Dense"
    if ipc_filters:
        search_type += f" (IPC í•„í„°: {', '.join(ipc_filters)})"
        
    yield {"type": "progress", "percent": 25, "message": f"ğŸ” Step 2/5: {search_type} ê²€ìƒ‰ ì¤‘... (ì˜ˆìƒ: 4ì´ˆ)"}
    yield {"type": "step_info", "step": 2, "message": f"{search_type} ê²€ìƒ‰ ì¤‘... (3ê°€ì§€ ê´€ì )"}
    
    # Use Multi-Query Search (Parallel) -> Get Top 15 candidates
    queries, search_results = await agent.search_multi_query(
        user_idea, top_k=15, use_hybrid=use_hybrid, ipc_filters=ipc_filters
    )
    
    # Emit generated queries
    yield {"type": "queries", "data": queries}
    
    yield {"type": "progress", "percent": 45, "message": "âœ… Step 2 ì™„ë£Œ!"}
    yield {"type": "info", "message": f"âœ… {len(search_results)}ê°œ í›„ë³´ íŠ¹í—ˆ ë°œê²¬ (ì¤‘ë³µ ì œê±°ë¨)"}
    
    # Step 3: Reranking (~3ì´ˆ)
    if reranker and search_results:
        yield {"type": "progress", "percent": 50, "message": "ğŸ¯ Step 3/5: Cross-Encoder ì •ë°€ ì¬ì •ë ¬ ì¤‘... (ì˜ˆìƒ: 3ì´ˆ)"}
        yield {"type": "step_info", "step": 3, "message": "Cross-Encoder ì •ë°€ ì¬ì •ë ¬ ì¤‘..."}
        
        # Convert PatentSearchResult to dict for Reranker
        docs_for_rerank = []
        for r in search_results:
            docs_for_rerank.append({
                "doc_obj": r, # Keep original object reference
                "title": r.title,
                "abstract": r.abstract,
                "claims": r.claims
            })
        
        # reranker.rerank()ëŠ” CPU ë¸”ë¡œí‚¹ ë™ê¸° ì—°ì‚°ì´ë¯€ë¡œ
        # asyncio.to_thread()ë¡œ ìŠ¤ë ˆë“œí’€ì—ì„œ ì‹¤í–‰í•˜ì—¬ ì´ë²¤íŠ¸ ë£¨í”„ë¥¼ ë³´í˜¸í•©ë‹ˆë‹¤.
        reranked_docs = await asyncio.to_thread(
            reranker.rerank, user_idea, docs_for_rerank, top_k=5
        )
        
        # Update results list
        results = []
        for doc in reranked_docs:
            r = doc['doc_obj']
            results.append(r)
            
        yield {"type": "info", "message": f"âœ… Top 5 íŠ¹í—ˆ ì„ ì • ì™„ë£Œ (Reranked)"}
    else:
        results = search_results[:5]
        yield {"type": "info", "message": "âš ï¸ Reranker ë¯¸ì‚¬ìš© (Top 5 ë°˜í™˜)"}
        
    yield {"type": "progress", "percent": 60, "message": "âœ… Step 3 ì™„ë£Œ!"}
    
    # Step 4: Grading (~3ì´ˆ)
    yield {"type": "progress", "percent": 65, "message": "ğŸ“Š Step 4/5: ê´€ë ¨ì„± í‰ê°€ ì¤‘... (ì˜ˆìƒ: 3ì´ˆ)"}
    yield {"type": "step_info", "step": 4, "message": "LLM ê´€ë ¨ì„± í‰ê°€ ì¤‘..."}
    grading = await agent.grade_results(user_idea, results)
    yield {"type": "progress", "percent": 80, "message": "âœ… Step 4 ì™„ë£Œ!"}
    yield {"type": "info", "message": f"âœ… í‰ê·  ê´€ë ¨ì„± ì ìˆ˜: {grading.average_score:.2f}"}
    
    # Step 5: Streaming Analysis (~10ì´ˆ)
    yield {"type": "progress", "percent": 85, "message": "ğŸ§  Step 5/5: AI ë¶„ì„ ìŠ¤íŠ¸ë¦¬ë° ì¤‘... (ì˜ˆìƒ: 10ì´ˆ)"}
    yield {"type": "step_info", "step": 5, "message": "AIê°€ ë¶„ì„ ë‚´ìš©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤..."}
    
    streamed_text = ""
    async for stream_event in run_analysis_streaming(agent, user_idea, results):
        if stream_event["type"] == "stream_token":
            yield {"type": "stream_token", "content": stream_event["content"]}
        elif stream_event["type"] == "stream_full":
            streamed_text = stream_event["content"]
    
    # Also get structured analysis for result storage
    analysis = await agent.critical_analysis(user_idea, results)
    
    # Complete progress bar
    elapsed = time.time() - start_time
    yield {"type": "progress", "percent": 100, "message": f"âœ… ë¶„ì„ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ)"}
    
    # Build final result payload
    final_result = {
        "user_idea": user_idea,
        "search_results": [
            {
                "patent_id": getattr(r, 'publication_number', str(getattr(r, 'id', ''))),
                "title": r.title,
                "abstract": r.abstract,
                "claims": r.claims,
                "grading_score": getattr(r, 'grading_score', 0),
                "grading_reason": getattr(r, 'grading_reason', ""),
                "rrf_score": getattr(r, 'rrf_score', 0),
            }
            for r in results
        ],
        "analysis": {
            "similarity": {
                "score": getattr(analysis.similarity, 'score', 0),
                "common_elements": getattr(analysis.similarity, 'common_elements', []),
                "summary": getattr(analysis.similarity, 'summary', ""),
                "evidence": getattr(analysis.similarity, 'evidence_patents', []),
            },
            "infringement": {
                "risk_level": getattr(analysis.infringement, 'risk_level', "Unknown"),
                "risk_factors": getattr(analysis.infringement, 'risk_factors', []),
                "summary": getattr(analysis.infringement, 'summary', ""),
                "evidence": getattr(analysis.infringement, 'evidence_patents', []),
            },
            "avoidance": {
                "strategies": getattr(analysis.avoidance, 'strategies', []),
                "alternatives": getattr(analysis.avoidance, 'alternative_technologies', []),
                "summary": getattr(analysis.avoidance, 'summary', ""),
                "evidence": getattr(analysis.avoidance, 'evidence_patents', []),
            },
            "component_comparison": {
                "idea_components": getattr(analysis.component_comparison, 'idea_components', []),
                "matched_components": getattr(analysis.component_comparison, 'matched_components', []),
                "unmatched_components": getattr(analysis.component_comparison, 'unmatched_components', []),
                "risk_components": getattr(analysis.component_comparison, 'risk_components', []),
            },
            "conclusion": getattr(analysis, 'conclusion', ""),
        },
        "streamed_analysis": streamed_text,
        "timestamp": datetime.now().isoformat(),
        "search_type": "hybrid" if use_hybrid else "dense",
    }
    
    yield {"type": "result", "data": final_result}
