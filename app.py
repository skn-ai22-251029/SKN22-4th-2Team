"""
Short-Cut Main Application.
"""
import asyncio
import os
import streamlit as st
from dotenv import load_dotenv

# Load Environment Variables
load_dotenv()

# Streamlit Config (Must be first)
st.set_page_config(
    page_title="Short-Cut",
    page_icon="âš¡", 
    layout="wide",
    initial_sidebar_state="expanded",
)

# API Keys
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")

# Imports after page config
from src.session_manager import init_session_state, load_history, save_result_to_history
from src.ui.styles import get_main_css
from src.ui.components import render_header, render_sidebar, render_search_results, render_footer
from src.analysis_logic import run_full_analysis

# Initialize Session
init_session_state()
load_history()

# Apply Global CSS
st.markdown(get_main_css(), unsafe_allow_html=True)

# Render UI
render_header()

# Cached Resource Loading
@st.cache_resource
def load_db_client():
    """Load Pinecone + BM25 hybrid client (optimized for speed)."""
    from src.vector_db import PineconeClient
    try:
        # skip_init_check=True reduces 1-2 seconds of network IO during startup
        client = PineconeClient(skip_init_check=True) 
        return client
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

DB_CLIENT = load_db_client()

# Sidebar (Stats are fetched lazily inside components if needed)
use_hybrid, selected_ipc_codes = render_sidebar(OPENAI_API_KEY, DB_CLIENT)

# Main Content - Input
st.markdown("### ğŸ’¡ ì•„ì´ë””ì–´ ì…ë ¥")
st.caption("íŠ¹í—ˆë¡œ ì¶œì›í•˜ë ¤ëŠ” ì•„ì´ë””ì–´ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”. ìœ ì‚¬ íŠ¹í—ˆë¥¼ ì°¾ì•„ ì¹¨í•´ ë¦¬ìŠ¤í¬ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

user_idea = st.text_area(
    label="ì•„ì´ë””ì–´ ì„¤ëª…",
    placeholder="ì˜ˆ: ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë¬¸ì„œ ìš”ì•½ ì‹œìŠ¤í…œìœ¼ë¡œ, ê¸´ ë¬¸ì„œë¥¼ ì…ë ¥ë°›ì•„ í•µì‹¬ ë‚´ìš©ì„ ì¶”ì¶œí•˜ê³  ìš”ì•½ë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤...",
    height=120,
    label_visibility="collapsed",
)

# Analysis Check
can_analyze = (
    user_idea and 
    OPENAI_API_KEY and 
    DB_CLIENT
)

col1, col2, col3 = st.columns([1, 1, 1])
with col2:
    analyze_button = st.button(
        "ğŸ” íŠ¹í—ˆ ë¶„ì„ ì‹œì‘",
        type="primary",
        use_container_width=True,
        disabled=not can_analyze,
    )

if not can_analyze and user_idea:
    if not OPENAI_API_KEY:
        st.warning("âš ï¸ OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    elif not DB_CLIENT:
        st.warning("âš ï¸ DB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨.")

# Analysis Execution
if analyze_button and can_analyze:
    status_container = st.container()
    streaming_container = st.container()
    
    try:
        # Run async analysis natively
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        async def run_and_update_ui():
            user_id = st.session_state.get("user_id", "unknown")
            final_res = None
            
            progress_bar = status_container.progress(0, text="ğŸš€ ì¤€ë¹„ ì¤‘...")
            status = status_container.status("ğŸ” íŠ¹í—ˆ ë¶„ì„ ì‹œì‘...", expanded=True)
            
            stream_placeholder = streaming_container.empty()
            full_text = ""
            
            async for event in run_full_analysis(
                user_idea=user_idea,
                user_id=user_id,
                db_client=DB_CLIENT,
                history_manager=st.session_state.history_manager,
                use_hybrid=use_hybrid,
                ipc_filters=selected_ipc_codes
            ):
                if event["type"] == "progress":
                    progress_bar.progress(event["percent"], text=event["message"])
                elif event["type"] == "step_info":
                    status.write(f"**Step {event['step']}**: {event['message']}")
                elif event["type"] == "info":
                    status.write(event["message"])
                elif event["type"] == "queries":
                    with status.expander("ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ë³´ê¸°", expanded=False):
                        for i, q in enumerate(event["data"]):
                            st.write(f"**Q{i+1}**: {q}")
                elif event["type"] == "stream_token":
                    full_text += event["content"]
                    stream_placeholder.markdown(full_text + "â–Œ")
                elif event["type"] == "stream_full":
                    stream_placeholder.markdown(event["content"])
                elif event["type"] == "result":
                    final_res = event["data"]
            
            status.update(label="âœ… ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)
            return final_res
            
        result = loop.run_until_complete(run_and_update_ui())
        
        loop.close()
        
        # Save result
        save_result_to_history(result)
            
    except Exception as e:
        st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.info("ğŸ’¡ OpenAI API í‚¤ë¥¼ í™•ì¸í•˜ê±°ë‚˜, ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

# Results Display
if st.session_state.current_result:
    render_search_results(st.session_state.current_result)

# Footer
render_footer()
